Prequirements:
1.create s3 bucket for backup
2.create kops user in IAM and give admin permission
3.lanuch ec2 instance
4.aws configure secrets keys 
5.ssh-keygen public and private keys to communicate  path  ls ./ssh

####
// installl kubectl 
step 1: install kubectl

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
chmod +x kubectl
mkdir -p ~/.local/bin
mv ./kubectl ~/.local/bin/kubectl
# and then append (or prepend) ~/.local/bin to $PATH
sudo kubectl version --client

#####
// To install Kops :

1.kops command for creating your cluster:

kops create cluster \
  --name=deepakram.k8s.local \
  --state=s3://backup.aws123 \
  --zones=us-east-1a,us-east-1b \
  --node-count=2 \
  --node-size=t2.micro \
  --master-size=t2.medium \
  --master-count=1

####
2. Then apply the changes (this actually builds the cluster):

kops update cluster \
  --name=deepakram.k8s.local \
  --state=s3://backup.aws123 \
  --yes

####
3. Validate cluster (this checks when the API server and nodes are up):

kops update cluster --name=deepakram.k8s.local --state=s3://backup.aws123 --yes --admin


####
4. Perform rolling update (to refresh instances and fully apply config):

kops rolling-update cluster \
  --name=deepakram.k8s.local \
  --state=s3://backup.aws123 \
  --yes

####

5. Check nodes:
   kubectl get nodes

####

6. Copy the kubeconfig from your kOps admin machine       To acces in master from created serevr
cat ~/.kube/config
scp ~/.kube/config ubuntu@<MASTER_IP>:/home/ubuntu/.kube/config

####
7. To delete cluster

kops delete cluster --name=deepakram.k8s.local --state=s3://backup.aws123 --yes

Kubernetes GUI

1. If you want a GUI (like Rancher) Install the Kubernetes Dashboard:
   kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

2. Then create a service account and access token:
  kubectl create serviceaccount admin-user -n kubernetes-dashboard

kubectl create clusterrolebinding admin-user-binding \
  --clusterrole=cluster-admin \
  --serviceaccount=kubernetes-dashboard:admin-user

kubectl -n kubernetes-dashboard create token admin-user

3. Access Dashboard
   kubectl proxy

4. Paste the token you generated with:
   kubectl -n kubernetes-dashboard create token admin-user

5. Use LoadBalancer (direct access)  Instead of proxy, expose Dashboard with a LoadBalancer:
   kubectl -n kubernetes-dashboard edit service kubernetes-dashboard

6. Change type: ClusterIP ‚ûù type: LoadBalancer.
   kubectl -n kubernetes-dashboard get svc

7. verfiy 
   https://a479c8717c2494c6fbnbknlbfknzonlkzsd49e85e02-1489136487.us-east-1.elb.amazonaws.com:443

